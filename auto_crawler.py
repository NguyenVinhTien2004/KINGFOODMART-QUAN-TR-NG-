import os
import sys
from datetime import datetime
import schedule
import time

# ThÃªm Ä‘Æ°á»ng dáº«n
sys.path.append('d:/Jupyter notebook/KingfoodMart')

from crawl_kf import fetch_and_save_products

def load_categories():
    """Äá»c danh sÃ¡ch categories tá»« file txt"""
    categories = []
    try:
        with open('d:/Jupyter notebook/KingfoodMart/category_url.txt', 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and line.startswith('https://'):  # Chá»‰ láº¥y URL há»£p lá»‡
                    categories.append(line)
        print(f"ğŸ“ Loaded {len(categories)} categories")
        return categories
    except Exception as e:
        print(f"âŒ Error loading categories: {e}")
        return []

def extract_slug_from_url(url):
    """TrÃ­ch xuáº¥t slug tá»« URL"""
    # https://kingfoodmart.com/hang-thung-gia-tot -> hang-thung-gia-tot
    slug = url.split('/')[-1]
    return slug

def daily_crawl_job():
    """Crawl táº¥t cáº£ categories tá»« file"""
    print(f"ğŸ•™ Starting daily crawl at {datetime.now()}")
    
    categories = load_categories()
    
    for i, category_url in enumerate(categories, 1):
        try:
            slug = extract_slug_from_url(category_url)
            
            print(f"ğŸ“‚ [{i}/{len(categories)}] Crawling: {slug}")
            
            fetch_and_save_products(
                start_page=1,
                end_page=5,
                limit_value=102,
                slug_value=slug,
                target_date=datetime.now()
            )
            
            print(f"âœ… Completed: {slug}")
            time.sleep(3)  # Nghá»‰ 3s giá»¯a cÃ¡c category Ä‘á»ƒ trÃ¡nh spam
            
        except Exception as e:
            print(f"âŒ Error crawling {slug}: {e}")
            continue  # Tiáº¿p tá»¥c vá»›i category tiáº¿p theo
    
    print(f"ğŸ‰ All categories completed at {datetime.now()}")

def main():
    """HÃ m chÃ­nh Ä‘á»ƒ cháº¡y láº­p lá»‹ch"""
    print("ğŸ¤– Starting automated crawler scheduler...")
    
    # Láº­p lá»‹ch cháº¡y hÃ ng ngÃ y lÃºc 10h tá»‘i
    schedule.every().day.at("22:00").do(daily_crawl_job)
    
    # Cháº¡y ngay láº§n Ä‘áº§u Ä‘á»ƒ test
    print("ğŸ§ª Running initial test...")
    daily_crawl_job()
    
    print("â° Scheduler started. Waiting for scheduled tasks...")
    
    # VÃ²ng láº·p chÃ­nh
    while True:
        schedule.run_pending()
        time.sleep(60)  # Kiá»ƒm tra má»—i phÃºt

if __name__ == "__main__":
    main()